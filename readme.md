### This readme file is written by ChatGPT as an output for the codebase I shared with it to explain nicely what is occuring in the codebase.

This code implements a neural network to play a game of rocket and land it safely by optimizing two target variables through backpropagation. The code begins with the import of necessary libraries such as NumPy, Pandas, Matplotlib, and Pickle. The `NeuralNetwork` class is defined next, which initializes with a random `lambda_val` and `learning_rate` value, defines the network's structure in the `layers` and `neurons` variables, and initializes empty `weights`, `input_value`, and `delta` lists.

The class includes various functions such as `set_neurons`, which sets the amount of neurons in each layer based on the input list `neurons`; `weight_multiplier`, which multiplies the input value and weights and returns the list of sums; `activation_function`, which calculates the activation function of the neuron using the sigmoid function; `error_calc`, which calculates the error between the actual and predicted values; `backprop`, which is currently an empty function but will be used to update the weights; `decay_lr`, which reduces the learning rate by a factor of 0.5; `regularizer_adjuster`, which adjusts the `lambda_val` regularization parameter; `outgradient`, which calculates the output layer gradient; `local_gradient`, which calculates the hidden layer gradient; and `weight_updation`, which updates the weights of the network.

Next, there are several utility functions such as `RMSE`, which calculates the root mean square error of a given error list; `save_weights`, which saves the input-hidden and hidden-output weights to a pickle file; `load_weights`, which loads the saved weights from the pickle file; `inference`, which takes the input data, saved weights, and Neural Network instance as inputs and returns the predicted output values; `test_network`, which takes the test data, saved weights, and Neural Network instance as inputs and returns the RMSE of the test data; and `control_the_network`, which takes the Neural Network instance, data, flag_quarter, flag_half, error list, and the current epoch number as inputs and adjusts the learning rate and `lambda_val` parameter accordingly.

There are several main functions such as `save_best_weights`, which saves the best weights for the input-hidden and hidden-output layers to a pickle file; `early_stopper`, which stops the training process early if the RMSE of the current epoch is worse than the previous epoch; and `main`, which reads the data, initializes the Neural Network instance, performs forward and backward propagation for a single epoch, calculates the RMSE of the current epoch, and updates the weights if the current epoch's RMSE is better than the previous epoch's RMSE. Finally, the function saves the best weights obtained during the training process and returns the RMSE values for each epoch.
